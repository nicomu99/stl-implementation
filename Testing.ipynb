{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "364e293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "from scipy.sparse import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c451cb",
   "metadata": {},
   "source": [
    "# The Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c5c58088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input:\n",
    "# A is a numpy matrix mxn\n",
    "# P_c is a permutation matrix as an int ndarray of shape (N,)\n",
    "# k is an integer\n",
    "# output:\n",
    "# Q_k is a numpy matrix\n",
    "# R_k is a numpy matrix\n",
    "def lu_crtp_4(A, P_c, k):\n",
    "    AP_c = A[:, P_c]\n",
    "    AP_c_selected_columns = AP_c[:, :k]\n",
    "    Q_k, R_k = np.linalg.qr(AP_c_selected_columns)\n",
    "    return Q_k, R_k\n",
    "\n",
    "# input:\n",
    "# a is a numpy matrix mxn\n",
    "# k is an even integer\n",
    "def lu_crtp(a, k, debug=False):\n",
    "    # According to https://epubs-siam-org.uaccess.univie.ac.at/doi/epdf/10.1137/13092157X QR_TP is the same\n",
    "    # as RRQR. For a faster implementation, we therefore decided on using scipy's LAPACK interface.\n",
    "    # Select k columns by using QR with tournament pivoting on A\n",
    "    _, _, p_c = qr(a, pivoting=True)\n",
    "    #p_c = p_c[:k]\n",
    "\n",
    "\n",
    "    # Compute the thin QR factorization of the selected columns\n",
    "    q_k, r_k = lu_crtp_4(a, p_c, k)\n",
    "    if(debug):\n",
    "        print(\"q_k:\")\n",
    "        print(q_k.shape)\n",
    "        print(\"r_k:\")\n",
    "        print(r_k.shape)\n",
    "\n",
    "\n",
    "    # Select k rows by using QR with tournament pivoting on Q^T_k\n",
    "    _, _, p_r = qr(q_k.T, pivoting=True)\n",
    "    #p_r = p_r[:k]\n",
    "\n",
    "    # Let A_ = P ...\n",
    "    a_dash = a[p_r,:]\n",
    "    a_dash = a_dash[:,p_c]\n",
    "    rows, cols = a_dash.shape\n",
    "    if(debug):\n",
    "        print(\"a_dash:\")\n",
    "        print(a_dash.shape)\n",
    "    \n",
    "    # Separate into block matrices\n",
    "    a_dash_11 = a_dash[:k, :k]\n",
    "    a_dash_21 = a_dash[k:, :k]\n",
    "    a_dash_12 = a_dash[:k, k:]\n",
    "    if(debug):\n",
    "        print(\"a_dash_11:\")\n",
    "        print(a_dash_11.shape)\n",
    "        print(\"a_dash_21:\")\n",
    "        print(a_dash_21.shape)\n",
    "        print(\"a_dash_12:\")\n",
    "        print(a_dash_12.shape)\n",
    "\n",
    "\n",
    "    # Compute L_21\n",
    "    inv_a_dash_11 = np.linalg.inv(a_dash_11)\n",
    "    l_21 = np.dot(a_dash_21, inv_a_dash_11)\n",
    "    if(debug):\n",
    "        print(\"l_21:\")\n",
    "        print(l_21.shape)\n",
    "\n",
    "    \n",
    "    # Stack the block matrices\n",
    "    i = np.identity(k)\n",
    "    l_k = np.vstack((i, l_21))\n",
    "    if(debug):\n",
    "        print(\"l_k:\")\n",
    "        print(l_k.shape)\n",
    "    u_k = np.hstack((a_dash_11, a_dash_12))\n",
    "    if(debug):\n",
    "        print(\"u_k:\")\n",
    "        print(u_k.shape)\n",
    "    return p_r, p_c, l_k, u_k, r_k\n",
    "\n",
    "# returns true if A and the approximation is equal\n",
    "def compareApprox(A, p_r, p_c, l_k, u_k):\n",
    "    approx = np.dot(l_k, u_k)\n",
    "    print(\"approx:\")\n",
    "    print(approx)\n",
    "    PA = p_A = A[p_r, :]\n",
    "    PA = p_A[:, p_c]\n",
    "    print(\"PA:\")\n",
    "    print(PA)\n",
    "    return np.allclose(approx, PA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2da4d7",
   "metadata": {},
   "source": [
    "# Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c55964fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recommender_System(orders, min_support, item_threshold=0.5):\n",
    "    mapped_records = []\n",
    "    # In the following tasks use the mapped records to compute the frequent itemsets.\n",
    "    for record in orders:\n",
    "        mapped_record = []\n",
    "        for index, item in enumerate(record):\n",
    "            if(item > item_threshold):\n",
    "                mapped_record.append(index)\n",
    "        mapped_record.sort()\n",
    "        mapped_records.append(mapped_record)\n",
    "\n",
    "        # Apriori Algorithm\n",
    "        l1_items = collections.Counter()\n",
    "        for record in mapped_records:\n",
    "            l1_items.update(record)\n",
    "        frequent_l1_items = {}\n",
    "        for item in l1_items:\n",
    "            support = l1_items[item]\n",
    "            if support >= min_support:\n",
    "                frequent_l1_items[(item,)] = support\n",
    "        frequent_itemsets = {}\n",
    "        for item in frequent_l1_items:\n",
    "            frequent_itemsets[item] = frequent_l1_items[item]\n",
    "        frequent_n_itemsets = frequent_l1_items\n",
    "        \n",
    "    def apriori_gen(itemsets):\n",
    "        C_k = set()\n",
    "        for p in itemsets:\n",
    "            for q in itemsets:\n",
    "                if p[-1] < q[-1]:\n",
    "                    C_k.add( p + (q[-1],) )\n",
    "        def all_subsets_in_itemsets(x):\n",
    "            for subset in itertools.combinations(x, len(x) - 1):\n",
    "                if subset not in itemsets:\n",
    "                    return False\n",
    "            return True\n",
    "        return list(filter(all_subsets_in_itemsets, C_k))\n",
    "\n",
    "    def calculate_support(itemset):\n",
    "        if len(itemset) == 1:\n",
    "            try:\n",
    "                return frequent_l1_items[itemset]\n",
    "            except KeyError:\n",
    "                return 0\n",
    "        support = 0\n",
    "        for record in mapped_records:\n",
    "            itemset_in_record = True\n",
    "            for item in itemset:\n",
    "                if item not in record:\n",
    "                    itemset_in_record = False\n",
    "                    break\n",
    "            if itemset_in_record:\n",
    "                support += 1\n",
    "        return support\n",
    "\n",
    "    while len(frequent_n_itemsets) != 0:\n",
    "        candidates = apriori_gen(frequent_n_itemsets)\n",
    "        supports = map(calculate_support, candidates)\n",
    "        frequent_candidates = {}\n",
    "        for candidate, support in zip(candidates, supports):\n",
    "            if support >= min_support:\n",
    "                frequent_candidates[candidate] = support\n",
    "        for item in frequent_candidates:\n",
    "            frequent_itemsets[item] = frequent_candidates[item]\n",
    "        frequent_n_itemsets = [itemset for itemset in frequent_candidates]\n",
    "\n",
    "    return frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a6e52880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_support(supports):\n",
    "    for itemset in supports:\n",
    "        support = supports[itemset]\n",
    "        print(f\"{itemset} : {support}\")\n",
    "        \n",
    "def compare_supports(supports1, supports2):\n",
    "    dist = 0\n",
    "    for itemset in supports1:\n",
    "        support1 = supports1[itemset]\n",
    "        support2 = supports2.get(itemset, 0)\n",
    "        dist = dist + np.square(support1 - support2)\n",
    "    for itemset in supports2:\n",
    "        support2 = supports2[itemset]\n",
    "        if(itemset not in supports1):\n",
    "            dist = dist + np.square(support2)            \n",
    "    return np.sqrt(dist)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eb3747",
   "metadata": {},
   "source": [
    "# Generate Random Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a9630862",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (25, 20)\n",
    "if(shape[0] < shape[1]):\n",
    "    print(\"we need more users than items to use the approximation for the recommender system!\")\n",
    "density = 0.2\n",
    "rng = np.random.default_rng(1234);\n",
    "\n",
    "random_matrix = random(*shape, density=density, format='csr', random_state=rng)\n",
    "random_matrix.data[:] = 1\n",
    "original = random_matrix.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75ba053",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "925f8569",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "p_r, p_c, l_k, u_k, r_k = lu_crtp(original, k, debug=False)\n",
    "approx = np.dot(l_k, u_k)\n",
    "\n",
    "pivoted_original = original[:, p_c]\n",
    "rounded_approx = np.where(approx > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "435df8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(original)\n",
    "print(pivoted_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3744ea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_support = 10;\n",
    "original_support = Recommender_System(pivoted_original, min_support)\n",
    "approx_support = Recommender_System(rounded_approx, min_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f1083b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pivoted_original.shape=(50, 25)\n",
      "rounded_approx.shape=(50, 25)\n",
      "\n",
      "support1=14 support2=14 dist=0\n",
      "support1=13 support2=13 dist=0\n",
      "support1=11 support2=11 dist=0\n",
      "support1=12 support2=12 dist=0\n",
      "support1=10 support2=10 dist=0\n",
      "support1=11 support2=11 dist=0\n",
      "support1=10 support2=10 dist=0\n",
      "support1=11 support2=11 dist=0\n",
      "support1=10 support2=10 dist=0\n",
      "support1=12 support2=12 dist=0\n",
      "support1=13 support2=13 dist=0\n",
      "support1=11 support2=11 dist=0\n",
      "support1=10 support2=10 dist=0\n",
      "support1=10 support2=10 dist=0\n",
      "support1=12 support2=14 dist=4\n",
      "support1=10 support2=10 dist=4\n",
      "support1=10 dist=229\n",
      "support1=10 dist=373\n",
      "support1=10 dist=517\n",
      "22.737634001804146\n"
     ]
    }
   ],
   "source": [
    "print(f\"{pivoted_original.shape=}\")\n",
    "print(f\"{rounded_approx.shape=}\")\n",
    "print(\"\")\n",
    "print(compare_supports(original_support, approx_support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eb9063a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_support:\n",
      "(0,) : 14\n",
      "(2,) : 13\n",
      "(7,) : 11\n",
      "(8,) : 12\n",
      "(12,) : 10\n",
      "(5,) : 11\n",
      "(17,) : 10\n",
      "(10,) : 11\n",
      "(11,) : 10\n",
      "(1,) : 12\n",
      "(3,) : 13\n",
      "(4,) : 11\n",
      "(6,) : 10\n",
      "(9,) : 10\n",
      "(20,) : 12\n",
      "(16,) : 10\n",
      "approx_support:\n",
      "(1,) : 12\n",
      "(2,) : 13\n",
      "(5,) : 11\n",
      "(8,) : 12\n",
      "(10,) : 11\n",
      "(23,) : 15\n",
      "(6,) : 10\n",
      "(17,) : 10\n",
      "(20,) : 14\n",
      "(0,) : 14\n",
      "(9,) : 10\n",
      "(16,) : 10\n",
      "(22,) : 12\n",
      "(3,) : 13\n",
      "(7,) : 11\n",
      "(21,) : 12\n",
      "(4,) : 11\n",
      "(11,) : 10\n",
      "(12,) : 10\n"
     ]
    }
   ],
   "source": [
    "print(\"original_support:\")\n",
    "print_support(original_support)\n",
    "print(\"approx_support:\")\n",
    "print_support(approx_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e15e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
